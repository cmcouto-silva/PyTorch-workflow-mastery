{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first cell set the working directory as the project directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cmcouto-silva/Projects/github/pytorch-workflow-mastery\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().endswith('notebooks'):\n",
    "    os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torchmetrics\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional] Enable TF32 for better performance on modern NVIDIA GPUs\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set available device (CPU or GPU - cuda)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "seed = 42\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 3\n",
    "batch_size = 128  # Larger batches for faster training\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model parameters\n",
    "num_classes = 10  # CIFAR10 has 10 classes\n",
    "model_path = 'weights/cifar10_model.pt'  # Path to save/load model weights\n",
    "\n",
    "# DataLoader settings\n",
    "train_num_workers = 4  # Number of parallel processes for data loading\n",
    "test_num_workers = 4   # Increase these if you have more CPU cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Set seeds -- ##\n",
    "\n",
    "# CPU seed\n",
    "torch.manual_seed(seed)  # Controls random number generation for PyTorch CPU operations\n",
    "\n",
    "# NumPy seed (for data loading/processing)\n",
    "np.random.seed(seed)     # Controls random number generation for NumPy operations\n",
    "\n",
    "# If GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # GPU seed\n",
    "    torch.cuda.manual_seed(seed)  # Controls random number generation for PyTorch GPU operations\n",
    "    # Force CUDA to use deterministic algorithms\n",
    "    torch.backends.cudnn.deterministic = False  # Makes GPU operations deterministic (might be slower)\n",
    "    \n",
    "# Set `deterministic = False` because we'll prioritize performance over reproducibility =S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight & Biases Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key is loaded (don't print in production!)\n",
    "assert os.getenv(\"WANDB_API_KEY\") is not None, \"WANDB_API_KEY not found in environment variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rest of your wandb setup remains the same\n",
    "wandb.init(\n",
    "    project=\"pytorch-cifar10\",\n",
    "    config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"model\": \"ResNet18\",\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"architecture\": \"Modified for CIFAR10\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For real-life applications, the image folder is usually structured as:\n",
    "\n",
    "```text\n",
    "data/\n",
    "├── train/\n",
    "│   ├── airplane/        # This folder name becomes class 0\n",
    "│   │   ├── img1.jpg\n",
    "│   │   ├── img2.jpg\n",
    "│   ├── automobile/      # This folder name becomes class 1\n",
    "│   │   ├── img1.jpg\n",
    "│   │   ├── img2.jpg\n",
    "│   └── ...\n",
    "├── val/\n",
    "│   ├── airplane/\n",
    "│   ├── automobile/\n",
    "│   └── ...\n",
    "└── test/\n",
    "    ├── airplane/\n",
    "    ├── automobile/\n",
    "    └── ...\n",
    "```\n",
    "\n",
    "So we can use `torchvision.datasets.ImageFolder` to load the dataset, passing it to `DataLoader` as shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformers\n",
    "\n",
    "train_transformer = transforms.Compose([   # Transformations like resizing and normalizaing alongside data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([     # Usually Resizing and normalizaton without data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "test_transformer = transforms.Compose([    # Usually same as validation transformation \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Download & load data -- ##\n",
    "\n",
    "# Datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transformer)\n",
    "val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_transformer)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=train_num_workers,\n",
    "    pin_memory = True,\n",
    "\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=train_num_workers,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "# Test set -> not available in this example, but real-life applications require test data - mainly when tuning hyperparameters!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify the final layer for CIFAR-10 (10 classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "# Set it to target device\n",
    "model = model.to(device)\n",
    "\n",
    "# Compile model to make it faster (torch>=2.0)\n",
    "model = torch.compile(model)\n",
    "\n",
    "# Set up loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "train_loss = torchmetrics.MeanMetric().to(device)\n",
    "val_loss = torchmetrics.MeanMetric().to(device)\n",
    "train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Starting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    ## -- Train step -- ##\n",
    "    \n",
    "    model.train()\n",
    "    train_loss.reset()\n",
    "    train_accuracy.reset()\n",
    "\n",
    "    train_progress = tqdm(train_loader, desc=f'• Epoch {epoch + 1}/{num_epochs} [Train]', leave=False)\n",
    "\n",
    "    for images, labels in train_progress:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update metrics\n",
    "        train_loss.update(loss)\n",
    "        train_accuracy.update(outputs, labels)\n",
    "\n",
    "        train_progress.set_postfix({\n",
    "            'loss': f'{train_loss.compute():.3f}',\n",
    "            'acc': f'{train_accuracy.compute():.1%}'\n",
    "        })\n",
    "\n",
    "    ## -- Validation step -- ##\n",
    "\n",
    "    model.eval()\n",
    "    val_loss.reset()\n",
    "    val_accuracy.reset()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        val_progress = tqdm(\n",
    "            val_loader, desc=f'• Epoch {epoch + 1}/{num_epochs} [Valid]', leave=False\n",
    "        )\n",
    "\n",
    "        for images, labels in val_progress:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Update metrics\n",
    "            val_loss.update(loss)\n",
    "            val_accuracy.update(outputs, labels)\n",
    "            \n",
    "            val_progress.set_postfix({\n",
    "                'loss': f'{val_loss.compute():.3f}',\n",
    "                'acc': f'{val_accuracy.compute():.1%}'\n",
    "            })\n",
    "\n",
    "    # Print epoch summary\n",
    "    logger.debug(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "        f\"Train Loss: {train_loss.compute():.3f} | \"\n",
    "        f\"Train Acc: {train_accuracy.compute():.1%} | \"\n",
    "        f\"Val Loss: {val_loss.compute():.3f} | \"\n",
    "        f\"Val Acc: {val_accuracy.compute():.1%}\"\n",
    "    )\n",
    "\n",
    "    # Log to wandb\n",
    "    wandb.log({\n",
    "        'epoch': epoch,\n",
    "        'train_loss': train_loss.compute(),\n",
    "        'train_accuracy': train_accuracy.compute(),\n",
    "        'val_loss': val_loss.compute(),\n",
    "        'val_accuracy': val_accuracy.compute()\n",
    "    })\n",
    "\n",
    "logger.success('Model trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fine-tuned model and training state\n",
    "torch.save({\n",
    "   'model_state_dict': model.state_dict(),          # Model weights\n",
    "   'optimizer_state_dict': optimizer.state_dict(),  # Optimizer state\n",
    "   'epoch': num_epochs,                             # Number of trained epochs\n",
    "}, model_path)\n",
    "\n",
    "logger.info(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "checkpoint = torch.load(model_path, weights_only=True)\n",
    "\n",
    "# Initialize model architecture\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Compile model as training\n",
    "model = model.to(device) \n",
    "model = torch.compile(model)\n",
    "\n",
    "# Load model weights\n",
    "model.load_state_dict(checkpoint['model_state_dict']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples to visualize\n",
    "n_samples = 10\n",
    "\n",
    "# Get random indices\n",
    "val_indices = np.random.choice(len(val_dataset), size=n_samples, replace=False)\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "# Get class names from CIFAR10\n",
    "classes = val_dataset.classes\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for idx, sample_idx in enumerate(val_indices):\n",
    "\n",
    "        # Get the image and label\n",
    "        image, true_label = val_dataset[sample_idx]\n",
    "        \n",
    "        # Add batch dimension and move to device\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get prediction\n",
    "        output = model(image)\n",
    "        predicted_label = output.argmax(1).item()\n",
    "        \n",
    "        # Convert image for display\n",
    "        img = image.cpu().squeeze()\n",
    "        img = img.permute(1, 2, 0)  # Change from CxHxW to HxWxC\n",
    "        \n",
    "        # Denormalize the image\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "        std = torch.tensor([0.229, 0.224, 0.225])\n",
    "        img = img * std + mean\n",
    "        \n",
    "        # Plot\n",
    "        plt.subplot(1, n_samples, idx + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        color = 'green' if predicted_label == true_label else 'red'\n",
    "        plt.title(\n",
    "            f'Pred: {classes[predicted_label]}\\n'\n",
    "            f'True: {classes[true_label]}',\n",
    "            color=color\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
